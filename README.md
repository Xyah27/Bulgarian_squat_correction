# Bulgarian Split Squat - Sistema de AnÃ¡lisis de Postura

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

Sistema de anÃ¡lisis automÃ¡tico de postura para el ejercicio Bulgarian Split Squat utilizando **MediaPipe Pose** y modelos **BiGRU con mecanismo de atenciÃ³n**.

## ğŸ“‹ CaracterÃ­sticas

- âœ… **DetecciÃ³n de postura en tiempo real** con MediaPipe Pose (33 landmarks)
- âœ… **ClasificaciÃ³n multi-etiqueta** de 4 tipos de postura:
  - `correcta`: TÃ©cnica correcta
  - `E1_tronco`: InclinaciÃ³n excesiva del tronco
  - `E2_valgo`: Valgo de rodilla (rodilla hacia dentro)
  - `E3_profundidad`: Profundidad insuficiente
- âœ… **Arquitectura BiGRU+Attention** (51.98% F1-score macro)
- âœ… **Inferencia en tiempo real** con webcam (~30 FPS)
- âœ… **DetecciÃ³n automÃ¡tica de vista** (frontal/lateral)
- âœ… **FSM para detecciÃ³n de repeticiones** automÃ¡tica

## ğŸ¯ Resultados del Modelo

| MÃ©trica | Valor |
|---------|-------|
| **F1-Score (Macro)** | 51.98% |
| **Accuracy** | 65.74% |
| **ParÃ¡metros** | 119,812 |
| **TamaÃ±o del modelo** | ~500 KB |

## ğŸ“ Estructura del Proyecto

```
bulgarian-split-squat/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ bulgarian_squat/          # Paquete principal
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ model_improved.py     # Arquitectura BiGRU+Attention
â”‚       â”œâ”€â”€ datamodule.py         # Carga y procesamiento de datos
â”‚       â”œâ”€â”€ train.py              # Funciones de entrenamiento
â”‚       â”œâ”€â”€ eval.py               # EvaluaciÃ³n y mÃ©tricas
â”‚       â”œâ”€â”€ rt_infer.py           # Inferencia en tiempo real
â”‚       â”œâ”€â”€ config.py             # ConfiguraciÃ³n global
â”‚       â”œâ”€â”€ features.py           # ExtracciÃ³n de caracterÃ­sticas
â”‚       â”œâ”€â”€ labels.py             # Procesamiento de etiquetas
â”‚       â”œâ”€â”€ splits.py             # Divisiones train/val/test
â”‚       â”œâ”€â”€ viz.py                # Visualizaciones
â”‚       â””â”€â”€ data_utils.py         # Utilidades de datos
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ train_bigru.py        # Script de entrenamiento
â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â””â”€â”€ run_webcam.py         # Inferencia con webcam
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ prepare_artifacts.py  # Preparar artifacts de modelo
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Datos originales
â”‚   â”‚   â””â”€â”€ landmarks_dataset_BALANCEADO_v2.csv
â”‚   â””â”€â”€ processed/                # Datos procesados
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best/                     # Mejor modelo entrenado
â”‚   â”‚   â”œâ”€â”€ best_model_bigru.pt
â”‚   â”‚   â”œâ”€â”€ run_meta.json
â”‚   â”‚   â”œâ”€â”€ class_names.json
â”‚   â”‚   â””â”€â”€ thr_per_class.npy
â”‚   â””â”€â”€ checkpoints/              # Checkpoints de entrenamiento
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ papers/                   # ArtÃ­culos y documentaciÃ³n
â”‚   â”‚   â””â”€â”€ paper_bulgarian_squat_es.pdf
â”‚   â””â”€â”€ figures/                  # Figuras y grÃ¡ficos
â”‚       â”œâ”€â”€ architecture_diagram.pdf
â”‚       â”œâ”€â”€ bigru_architecture.pdf
â”‚       â”œâ”€â”€ confusion_matrix_normalized.pdf
â”‚       â””â”€â”€ attention_weights_visualization.pdf
â”‚
â”œâ”€â”€ configs/                      # Archivos de configuraciÃ³n
â”œâ”€â”€ notebooks/                    # Jupyter notebooks de anÃ¡lisis
â”œâ”€â”€ logs/                         # Logs de entrenamiento
â”œâ”€â”€ requirements.txt              # Dependencias del proyecto
â”œâ”€â”€ setup.py                      # InstalaciÃ³n del paquete
â”œâ”€â”€ .gitignore                    # Archivos ignorados por git
â””â”€â”€ README.md                     # Este archivo
```

## ğŸš€ InstalaciÃ³n

### Prerrequisitos

- Python 3.8 o superior
- pip
- (Opcional) CUDA para aceleraciÃ³n GPU

### Paso 1: Clonar el repositorio

```bash
git clone https://github.com/tu-usuario/bulgarian-split-squat.git
cd bulgarian-split-squat
```

### Paso 2: Crear entorno virtual (recomendado)

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### Paso 3: Instalar dependencias

```bash
pip install -r requirements.txt
```

O instalar el paquete en modo desarrollo:

```bash
pip install -e .
```

## ğŸ“¦ Dependencias Principales

- **PyTorch** (>= 2.0.0): Framework de deep learning
- **MediaPipe** (>= 0.10.0): DetecciÃ³n de pose
- **OpenCV** (>= 4.8.0): Procesamiento de video
- **NumPy** (>= 1.24.0): Operaciones numÃ©ricas
- **pandas** (>= 2.0.0): ManipulaciÃ³n de datos
- **scikit-learn** (>= 1.3.0): MÃ©tricas y utilidades
- **matplotlib** (>= 3.7.0): Visualizaciones
- **seaborn** (>= 0.12.0): Visualizaciones estadÃ­sticas

## ğŸ“ Uso

### 1. Inferencia en Tiempo Real con Webcam

Ejecutar el sistema de anÃ¡lisis con tu cÃ¡mara:

```bash
python scripts/inference/run_webcam.py --model models/best --cam 0
```

**Opciones:**
- `--model`: Directorio con el modelo entrenado (default: `models/best`)
- `--cam`: Ãndice de la cÃ¡mara (default: `0`)
  - Intenta `--cam 1`, `--cam 2`, etc. si la cÃ¡mara principal no funciona
- `--minlen`: MÃ­nimo de frames por repeticiÃ³n (default: `20`)
- `--maxlen`: MÃ¡ximo de frames por repeticiÃ³n (default: `90`)

**Controles en tiempo de ejecuciÃ³n:**
- **D**: Activar/desactivar modo debug (muestra mÃ©tricas de detecciÃ³n)
- **ESPACIO**: Modo captura manual on/off
- **Q o ESC**: Salir

**Consejos para mejor detecciÃ³n:**
- âœ… ColÃ³cate en **vista lateral** o **frontal** completa
- âœ… AsegÃºrate de que todo tu cuerpo sea visible
- âœ… Realiza movimientos **lentos y controlados** (2-3 segundos por repeticiÃ³n)
- âœ… Buena iluminaciÃ³n y fondo contrastante

### 2. Entrenar un Modelo Nuevo

Entrenar desde cero con tu propio dataset:

```bash
python scripts/training/train_bigru.py \
    --dataset data/raw/landmarks_dataset_BALANCEADO_v2.csv \
    --epochs 100 \
    --batch_size 32 \
    --lr 0.001 \
    --hidden1 128 \
    --hidden2 64 \
    --dropout 0.3 \
    --use_attention \
    --output_dir models/checkpoints \
    --patience 15
```

**Argumentos principales:**
- `--dataset`: Ruta al archivo CSV con los datos
- `--epochs`: NÃºmero de Ã©pocas de entrenamiento
- `--batch_size`: TamaÃ±o del batch
- `--lr`: Learning rate
- `--hidden1`, `--hidden2`: TamaÃ±os de capas ocultas
- `--dropout`: Tasa de dropout
- `--use_attention`: Activar mecanismo de atenciÃ³n
- `--patience`: Paciencia para early stopping
- `--output_dir`: Directorio para guardar checkpoints

El script genera:
- `best_model.pt`: Pesos del mejor modelo
- `run_meta.json`: Metadatos y configuraciÃ³n
- `class_names.json`: Nombres de las clases
- `thr_per_class.npy`: Umbrales Ã³ptimos por clase

### 3. Preparar Artifacts para Inferencia

Si entrenaste un modelo nuevo, prepara los artifacts:

```bash
python scripts/utils/prepare_artifacts.py \
    --model models/checkpoints/bigru_20241106_123456/best_model.pt \
    --output models/best
```

## ğŸ“Š Formato del Dataset

El dataset debe ser un archivo CSV con las siguientes columnas:

```csv
frame_id,video_name,landmark_0_x,landmark_0_y,...,landmark_32_x,landmark_32_y,correcta,E1_tronco,E2_valgo,E3_profundidad
0,video1.mp4,0.5,0.3,...,0.6,0.8,1,0,0,0
1,video1.mp4,0.51,0.31,...,0.61,0.81,1,0,0,0
...
```

**CaracterÃ­sticas:**
- **Landmarks**: 33 puntos Ã— 2 coordenadas (x, y) = 66 features
- **Etiquetas**: Multi-etiqueta binaria (0 o 1) para cada clase
- **Frames**: Secuencias de frames agrupados por `video_name`

## ğŸ§ª Arquitectura del Modelo

```
Input (T, 66)
    â†“
BatchNorm1d
    â†“
BiGRU Layer 1 (hidden_size=128)
    â†“
LayerNorm + Dropout(0.3)
    â†“
BiGRU Layer 2 (hidden_size=64)
    â†“
LayerNorm + Dropout(0.3)
    â†“
Attention Mechanism
    â†“
Weighted Sum (context vector)
    â†“
Fully Connected (64 â†’ 4)
    â†“
Output (4 clases)
```

## ğŸ”¬ EvaluaciÃ³n

Para evaluar un modelo en el conjunto de test:

```python
from bulgarian_squat import BiGRUClassifierImproved
from bulgarian_squat.datamodule import BulgarianSquatDataModule
from bulgarian_squat.eval import evaluate_model

# Cargar datos
dm = BulgarianSquatDataModule(csv_path="data/raw/dataset.csv")
dm.setup()
test_loader = dm.test_dataloader()

# Cargar modelo
model = BiGRUClassifierImproved(in_dim=66, num_classes=4)
model.load_state_dict(torch.load("models/best/best_model_bigru.pt"))
model.eval()

# Evaluar
test_loss, metrics = evaluate_model(model, test_loader, criterion, device, verbose=True)
```

## ğŸ“ˆ Resultados Detallados por Clase

| Clase | Precision | Recall | F1-Score |
|-------|-----------|--------|----------|
| **correcta** | 0.79 | 0.82 | 0.81 |
| **E1_tronco** | 0.44 | 0.34 | 0.38 |
| **E2_valgo** | 0.29 | 0.10 | 0.15 |
| **E3_profundidad** | 0.72 | 0.93 | 0.81 |

**Umbrales Ã³ptimos:**
- correcta: 0.31
- E1_tronco: 0.19
- E2_valgo: 0.10
- E3_profundidad: 0.70

## ğŸ› ï¸ Desarrollo

### Estructura Modular

El cÃ³digo estÃ¡ organizado en mÃ³dulos independientes para facilitar mantenimiento:

- **models**: DefiniciÃ³n de arquitecturas
- **data**: Carga y preprocesamiento
- **training**: Loops de entrenamiento
- **evaluation**: MÃ©tricas y validaciÃ³n
- **inference**: Inferencia en producciÃ³n
- **utils**: Utilidades compartidas

### Agregar Nuevos Modelos

1. Crear archivo en `src/bulgarian_squat/model_nuevo.py`
2. Heredar de `nn.Module` e implementar `forward(x, mask)`
3. Registrar en `__init__.py`
4. Crear script de entrenamiento en `scripts/training/`

### Agregar Nuevas CaracterÃ­sticas

1. Modificar `features.py` para extraer nuevas caracterÃ­sticas
2. Actualizar `in_dim` en configuraciÃ³n del modelo
3. Re-entrenar con nuevo dataset

## ğŸ“ CitaciÃ³n

Si utilizas este proyecto en tu investigaciÃ³n, por favor cita:

```bibtex
@article{bulgarian_squat_2024,
  title={AnÃ¡lisis AutomÃ¡tico de Postura en Bulgarian Split Squat usando BiGRU con AtenciÃ³n},
  author={Tu Nombre},
  journal={Conference/Journal Name},
  year={2024}
}
```

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas! Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“§ Contacto

- **Autor**: Tu Nombre
- **Email**: tu.email@example.com
- **Proyecto**: [https://github.com/tu-usuario/bulgarian-split-squat](https://github.com/tu-usuario/bulgarian-split-squat)

## ğŸ™ Agradecimientos

- **MediaPipe** por la detecciÃ³n de pose de alta calidad
- **PyTorch** por el framework de deep learning
- Comunidad de investigaciÃ³n en visiÃ³n por computadora

## ğŸ“š Referencias

1. MediaPipe Pose: [https://google.github.io/mediapipe/solutions/pose](https://google.github.io/mediapipe/solutions/pose)
2. BiGRU Networks: Bidirectional Gated Recurrent Units
3. Attention Mechanisms in Deep Learning
4. Multi-label Classification for Pose Assessment

---

**ğŸ‹ï¸ Â¡Entrena con tÃ©cnica correcta! ğŸ‹ï¸**
