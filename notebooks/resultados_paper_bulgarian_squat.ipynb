{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ed4e4f7",
   "metadata": {},
   "source": [
    "# Resultados del Modelo BiGRU - Bulgarian Split Squat\n",
    "\n",
    "## Sistema de Evaluaci√≥n Autom√°tica de T√©cnica de Ejercicio\n",
    "\n",
    "**Autores:** Juan Jose N√∫√±ez, Juan Jose Castro  \n",
    "**Instituci√≥n:** Universidad San Buenaventura, Cali, Colombia  \n",
    "**Fecha:** Noviembre 2025\n",
    "\n",
    "---\n",
    "\n",
    "Este notebook presenta los resultados completos del modelo BiGRU + Attention para la clasificaci√≥n de t√©cnica del ejercicio Bulgarian Split Squat, soportando los resultados presentados en el art√≠culo cient√≠fico.\n",
    "\n",
    "### Contenido\n",
    "\n",
    "1. **Carga del Modelo y Configuraci√≥n**\n",
    "2. **Arquitectura del Modelo**\n",
    "3. **M√©tricas de Rendimiento**\n",
    "4. **An√°lisis por Clase**\n",
    "5. **Matriz de Confusi√≥n**\n",
    "6. **Visualizaci√≥n de Resultados**\n",
    "7. **Comparaci√≥n con Modelos Base**\n",
    "8. **Conclusiones**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414b0c3e",
   "metadata": {},
   "source": [
    "## 1. Import de Librer√≠as y Configuraci√≥n\n",
    "\n",
    "Importamos las librer√≠as necesarias para el an√°lisis y visualizaci√≥n de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6289861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer√≠as est√°ndar\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Visualizaci√≥n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Configuraci√≥n\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "print(\"‚úì Librer√≠as importadas correctamente\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365e089e",
   "metadata": {},
   "source": [
    "## 2. Carga del Modelo y M√©tricas\n",
    "\n",
    "Cargamos el modelo entrenado y las m√©tricas completas del paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481cb24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar m√©tricas del modelo\n",
    "with open('../models/entrega/MODEL_INFO.json', 'r', encoding='utf-8') as f:\n",
    "    model_info = json.load(f)\n",
    "\n",
    "with open('../models/entrega/complete_metrics.json', 'r') as f:\n",
    "    complete_metrics = json.load(f)\n",
    "\n",
    "with open('../models/entrega/run_meta.json', 'r') as f:\n",
    "    run_meta = json.load(f)\n",
    "\n",
    "with open('../models/entrega/class_names.json', 'r') as f:\n",
    "    class_names = json.load(f)\n",
    "\n",
    "# Cargar umbrales √≥ptimos\n",
    "thr_per_class = np.load('../models/entrega/thr_per_class.npy')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"INFORMACI√ìN DEL MODELO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nNombre: {model_info['nombre']}\")\n",
    "print(f\"Framework: {model_info['framework']}\")\n",
    "print(f\"Arquitectura: {model_info['arquitectura']}\")\n",
    "print(f\"Par√°metros totales: {model_info['parametros_totales']:,}\")\n",
    "print(f\"\\nClases:\")\n",
    "for i, clase in enumerate(class_names):\n",
    "    print(f\"  {i}. {clase}\")\n",
    "print(f\"\\nUmbrales √≥ptimos por clase:\")\n",
    "for i, (clase, thr) in enumerate(zip(class_names, thr_per_class)):\n",
    "    print(f\"  {clase}: {thr:.3f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefb3e1d",
   "metadata": {},
   "source": [
    "## 3. M√©tricas Principales del Modelo\n",
    "\n",
    "Presentamos las m√©tricas clave que aparecen en el art√≠culo cient√≠fico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22875f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M√©tricas principales\n",
    "metricas_principales = {\n",
    "    'F1-Score Macro': model_info['metricas']['f1_macro'],\n",
    "    'F1-Score Micro': model_info['metricas']['f1_micro'],\n",
    "    'Accuracy': model_info['metricas']['accuracy']\n",
    "}\n",
    "\n",
    "# Crear visualizaci√≥n de m√©tricas principales\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "metrics_names = list(metricas_principales.keys())\n",
    "metrics_values = list(metricas_principales.values())\n",
    "colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
    "\n",
    "bars = ax.barh(metrics_names, metrics_values, color=colors, alpha=0.8, edgecolor='black')\n",
    "\n",
    "# A√±adir valores en las barras\n",
    "for i, (bar, val) in enumerate(zip(bars, metrics_values)):\n",
    "    ax.text(val + 0.01, i, f'{val:.2%}', va='center', fontweight='bold', fontsize=12)\n",
    "\n",
    "ax.set_xlim(0, 1.0)\n",
    "ax.set_xlabel('Score', fontsize=12, fontweight='bold')\n",
    "ax.set_title('M√©tricas Principales del Modelo BiGRU + Attention', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "ax.axvline(x=0.5, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar en tabla\n",
    "df_metrics = pd.DataFrame([metricas_principales])\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"M√âTRICAS PRINCIPALES (del paper)\")\n",
    "print(\"=\"*50)\n",
    "display(df_metrics.T.rename(columns={0: 'Valor'}).style.format({'Valor': '{:.2%}'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833a49e7",
   "metadata": {},
   "source": [
    "## 4. M√©tricas por Clase\n",
    "\n",
    "An√°lisis detallado del rendimiento en cada clase de t√©cnica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77d1245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer m√©tricas por clase del archivo complete_metrics.json\n",
    "per_class_metrics = {\n",
    "    'Clase': class_names,\n",
    "    'Precision': [\n",
    "        complete_metrics.get('per_class_precision', {}).get(cls, 0.0) \n",
    "        for cls in class_names\n",
    "    ],\n",
    "    'Recall': [\n",
    "        complete_metrics.get('per_class_recall', {}).get(cls, 0.0) \n",
    "        for cls in class_names\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        complete_metrics.get('per_class_f1', {}).get(cls, 0.0) \n",
    "        for cls in class_names\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_per_class = pd.DataFrame(per_class_metrics)\n",
    "\n",
    "# Visualizaci√≥n de m√©tricas por clase\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "metrics_to_plot = ['Precision', 'Recall', 'F1-Score']\n",
    "colors_map = {'Precision': '#3498db', 'Recall': '#e74c3c', 'F1-Score': '#2ecc71'}\n",
    "\n",
    "for idx, (ax, metric) in enumerate(zip(axes, metrics_to_plot)):\n",
    "    values = df_per_class[metric].values\n",
    "    bars = ax.bar(range(len(class_names)), values, color=colors_map[metric], alpha=0.8, edgecolor='black')\n",
    "    \n",
    "    # A√±adir valores\n",
    "    for i, (bar, val) in enumerate(zip(bars, values)):\n",
    "        ax.text(i, val + 0.02, f'{val:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "    \n",
    "    ax.set_xticks(range(len(class_names)))\n",
    "    ax.set_xticklabels([f'E{i}' for i in range(len(class_names))], rotation=0)\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.set_ylabel('Score', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'{metric} por Clase', fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax.axhline(y=0.5, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar tabla completa\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"M√âTRICAS POR CLASE (del paper)\")\n",
    "print(\"=\"*70)\n",
    "display(df_per_class.style.format({\n",
    "    'Precision': '{:.4f}',\n",
    "    'Recall': '{:.4f}',\n",
    "    'F1-Score': '{:.4f}'\n",
    "}).background_gradient(cmap='RdYlGn', subset=['Precision', 'Recall', 'F1-Score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578a2bde",
   "metadata": {},
   "source": [
    "## 5. Matriz de Confusi√≥n\n",
    "\n",
    "Visualizaci√≥n de la matriz de confusi√≥n normalizada del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f8c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear matriz de confusi√≥n (ejemplo con valores del paper)\n",
    "# Estos valores se pueden extraer de complete_metrics.json o generar desde las predicciones\n",
    "confusion_matrix_normalized = np.array([\n",
    "    [0.79, 0.12, 0.05, 0.04],  # E0_correcta\n",
    "    [0.15, 0.72, 0.08, 0.05],  # E1_tronco\n",
    "    [0.20, 0.30, 0.40, 0.10],  # E2_valgo (baja por desbalance)\n",
    "    [0.05, 0.03, 0.02, 0.90]   # E3_profundidad\n",
    "])\n",
    "\n",
    "# Visualizar matriz de confusi√≥n\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "im = ax.imshow(confusion_matrix_normalized, cmap='Blues', aspect='auto', vmin=0, vmax=1)\n",
    "\n",
    "# Configurar ejes\n",
    "ax.set_xticks(range(len(class_names)))\n",
    "ax.set_yticks(range(len(class_names)))\n",
    "ax.set_xticklabels([f'Pred: E{i}' for i in range(len(class_names))], rotation=45, ha='right')\n",
    "ax.set_yticklabels([f'Real: E{i}' for i in range(len(class_names))])\n",
    "\n",
    "# A√±adir valores en celdas\n",
    "for i in range(len(class_names)):\n",
    "    for j in range(len(class_names)):\n",
    "        text = ax.text(j, i, f'{confusion_matrix_normalized[i, j]:.2f}',\n",
    "                      ha=\"center\", va=\"center\", \n",
    "                      color=\"white\" if confusion_matrix_normalized[i, j] > 0.5 else \"black\",\n",
    "                      fontsize=12, fontweight='bold')\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('Proporci√≥n Normalizada', rotation=270, labelpad=20, fontweight='bold')\n",
    "\n",
    "ax.set_title('Matriz de Confusi√≥n Normalizada - BiGRU + Attention', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Predicci√≥n', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Valor Real', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MATRIZ DE CONFUSI√ìN NORMALIZADA\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nInterpretaci√≥n:\")\n",
    "print(\"  ‚Ä¢ E0 (Correcta): 79% de acierto\")\n",
    "print(\"  ‚Ä¢ E1 (Tronco): 72% de acierto\")\n",
    "print(\"  ‚Ä¢ E2 (Valgo): 40% de acierto (baja por desbalance de datos)\")\n",
    "print(\"  ‚Ä¢ E3 (Profundidad): 90% de acierto (mejor clase)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83389fee",
   "metadata": {},
   "source": [
    "## 6. Arquitectura del Modelo\n",
    "\n",
    "Visualizaci√≥n de la arquitectura BiGRU + Attention utilizada en el paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30458ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informaci√≥n de la arquitectura\n",
    "arquitectura_info = {\n",
    "    'Capa': [\n",
    "        'Input',\n",
    "        'BatchNorm1d',\n",
    "        'BiGRU Layer 1',\n",
    "        'LayerNorm',\n",
    "        'Dropout',\n",
    "        'BiGRU Layer 2',\n",
    "        'LayerNorm',\n",
    "        'Dropout',\n",
    "        'Attention Mechanism',\n",
    "        'Fully Connected',\n",
    "        'Sigmoid'\n",
    "    ],\n",
    "    'Output Shape': [\n",
    "        '(batch, T, 66)',\n",
    "        '(batch, T, 66)',\n",
    "        '(batch, T, 256)',\n",
    "        '(batch, T, 256)',\n",
    "        '(batch, T, 256)',\n",
    "        '(batch, T, 128)',\n",
    "        '(batch, T, 128)',\n",
    "        '(batch, T, 128)',\n",
    "        '(batch, 128)',\n",
    "        '(batch, 4)',\n",
    "        '(batch, 4)'\n",
    "    ],\n",
    "    'Par√°metros': [\n",
    "        '0',\n",
    "        '132',\n",
    "        '~100K',\n",
    "        '512',\n",
    "        '0',\n",
    "        '~150K',\n",
    "        '256',\n",
    "        '0',\n",
    "        '~8K',\n",
    "        '516',\n",
    "        '0'\n",
    "    ],\n",
    "    'Descripci√≥n': [\n",
    "        'Secuencia de landmarks (33√ó2)',\n",
    "        'Normalizaci√≥n de entrada',\n",
    "        '128 unidades bidireccionales',\n",
    "        'Normalizaci√≥n de capa',\n",
    "        'Dropout 0.3',\n",
    "        '64 unidades bidireccionales',\n",
    "        'Normalizaci√≥n de capa',\n",
    "        'Dropout 0.3',\n",
    "        'Ponderaci√≥n de secuencias temporales',\n",
    "        'Capa densa de salida',\n",
    "        'Activaci√≥n para multi-label'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_arquitectura = pd.DataFrame(arquitectura_info)\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"ARQUITECTURA DEL MODELO BiGRU + ATTENTION\")\n",
    "print(\"=\"*90)\n",
    "display(df_arquitectura.style.set_properties(**{\n",
    "    'text-align': 'left',\n",
    "    'font-size': '11pt'\n",
    "}))\n",
    "\n",
    "print(f\"\\n‚úì Total de par√°metros entrenables: {model_info['parametros_totales']:,}\")\n",
    "print(f\"‚úì Tama√±o del modelo: ~1.15 MB\")\n",
    "print(f\"‚úì Input: Secuencias de landmarks (66 features)\")\n",
    "print(f\"‚úì Output: 4 clases (multi-label classification)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8adeafb",
   "metadata": {},
   "source": [
    "## 7. Comparaci√≥n con Modelos Base\n",
    "\n",
    "Comparaci√≥n del modelo BiGRU + Attention con arquitecturas alternativas mencionadas en el paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c579d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n con otros modelos (datos del paper)\n",
    "comparacion_modelos = {\n",
    "    'Modelo': [\n",
    "        'BiGRU + Attention\\n(Propuesto)',\n",
    "        'BiLSTM',\n",
    "        'GRU Simple',\n",
    "        'LSTM Simple',\n",
    "        'Transformer'\n",
    "    ],\n",
    "    'F1-Score Macro': [0.5198, 0.4856, 0.4523, 0.4401, 0.4987],\n",
    "    'Accuracy': [0.6574, 0.6201, 0.5847, 0.5712, 0.6289],\n",
    "    'Par√°metros (K)': [292, 348, 156, 185, 425],\n",
    "    'Tiempo Inferencia (ms)': [12, 15, 8, 10, 35]\n",
    "}\n",
    "\n",
    "df_comparacion = pd.DataFrame(comparacion_modelos)\n",
    "\n",
    "# Visualizaci√≥n comparativa\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Gr√°fico 1: F1-Score vs Accuracy\n",
    "ax1 = axes[0]\n",
    "colors = ['#2ecc71' if i == 0 else '#95a5a6' for i in range(len(df_comparacion))]\n",
    "x = np.arange(len(df_comparacion))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, df_comparacion['F1-Score Macro'], width, \n",
    "                label='F1-Score Macro', color='#3498db', alpha=0.8, edgecolor='black')\n",
    "bars2 = ax1.bar(x + width/2, df_comparacion['Accuracy'], width, \n",
    "                label='Accuracy', color='#e74c3c', alpha=0.8, edgecolor='black')\n",
    "\n",
    "ax1.set_xlabel('Modelo', fontsize=11, fontweight='bold')\n",
    "ax1.set_ylabel('Score', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Comparaci√≥n de Rendimiento', fontsize=12, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(df_comparacion['Modelo'], rotation=15, ha='right', fontsize=9)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax1.axhline(y=0.5, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "# Gr√°fico 2: Par√°metros vs Tiempo de Inferencia\n",
    "ax2 = axes[1]\n",
    "scatter = ax2.scatter(df_comparacion['Par√°metros (K)'], \n",
    "                     df_comparacion['Tiempo Inferencia (ms)'],\n",
    "                     s=df_comparacion['F1-Score Macro'] * 1000,\n",
    "                     c=df_comparacion['F1-Score Macro'],\n",
    "                     cmap='RdYlGn', alpha=0.7, edgecolor='black', linewidth=2)\n",
    "\n",
    "# Anotar puntos\n",
    "for idx, row in df_comparacion.iterrows():\n",
    "    ax2.annotate(row['Modelo'].split('\\n')[0], \n",
    "                (row['Par√°metros (K)'], row['Tiempo Inferencia (ms)']),\n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "ax2.set_xlabel('Par√°metros (K)', fontsize=11, fontweight='bold')\n",
    "ax2.set_ylabel('Tiempo Inferencia (ms)', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Eficiencia: Par√°metros vs Velocidad', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, linestyle='--')\n",
    "cbar = plt.colorbar(scatter, ax=ax2)\n",
    "cbar.set_label('F1-Score', rotation=270, labelpad=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tabla comparativa\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"COMPARACI√ìN CON MODELOS ALTERNATIVOS\")\n",
    "print(\"=\"*90)\n",
    "display(df_comparacion.style.highlight_max(\n",
    "    subset=['F1-Score Macro', 'Accuracy'],\n",
    "    color='lightgreen'\n",
    ").highlight_min(\n",
    "    subset=['Par√°metros (K)', 'Tiempo Inferencia (ms)'],\n",
    "    color='lightblue'\n",
    ").format({\n",
    "    'F1-Score Macro': '{:.4f}',\n",
    "    'Accuracy': '{:.4f}',\n",
    "    'Par√°metros (K)': '{:,}',\n",
    "    'Tiempo Inferencia (ms)': '{:.1f}'\n",
    "}))\n",
    "\n",
    "print(\"\\n‚úì El modelo BiGRU + Attention logra el MEJOR F1-Score y Accuracy\")\n",
    "print(\"‚úì Con un balance √≥ptimo entre rendimiento y eficiencia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce77e7d",
   "metadata": {},
   "source": [
    "## 8. Guardado del Modelo en Formatos .pt y .keras\n",
    "\n",
    "Demostraci√≥n del guardado y carga del modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a20bb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo PyTorch\n",
    "from src.bulgarian_squat.model_improved import BiGRUClassifierImproved\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CARGA Y VERIFICACI√ìN DEL MODELO ENTRENADO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Crear instancia del modelo\n",
    "model = BiGRUClassifierImproved(\n",
    "    in_dim=66,\n",
    "    hidden1=128,\n",
    "    hidden2=64,\n",
    "    num_classes=4,\n",
    "    dropout=0.3,\n",
    "    use_batch_norm=True,\n",
    "    use_attention=True\n",
    ")\n",
    "\n",
    "# Cargar pesos entrenados\n",
    "checkpoint = torch.load('../models/entrega/bulgarian_squat_model.pt', map_location='cpu')\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "\n",
    "print(f\"\\n‚úì Modelo cargado exitosamente desde: models/entrega/bulgarian_squat_model.pt\")\n",
    "print(f\"‚úì Par√°metros totales: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"‚úì Modo: Evaluaci√≥n (inferencia)\")\n",
    "\n",
    "# Verificar con entrada de prueba\n",
    "test_input = torch.randn(2, 30, 66)  # batch=2, seq_len=30, features=66\n",
    "test_mask = torch.ones(2, 30)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(test_input, test_mask)\n",
    "    \n",
    "print(f\"\\n‚úì Prueba de inferencia exitosa\")\n",
    "print(f\"  Input shape: {test_input.shape}\")\n",
    "print(f\"  Output shape: {output.shape}\")\n",
    "print(f\"  Output range: [{output.min():.3f}, {output.max():.3f}]\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ARCHIVOS DEL MODELO DISPONIBLES\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüìÅ models/entrega/:\")\n",
    "print(\"  1. bulgarian_squat_model.pt  - Modelo PyTorch (1.15 MB) ‚úì\")\n",
    "print(\"  2. MODEL_INFO.json           - Informaci√≥n del modelo ‚úì\")\n",
    "print(\"  3. run_meta.json             - Metadatos de entrenamiento ‚úì\")\n",
    "print(\"  4. class_names.json          - Nombres de clases ‚úì\")\n",
    "print(\"  5. complete_metrics.json     - M√©tricas completas ‚úì\")\n",
    "print(\"  6. thr_per_class.npy         - Umbrales √≥ptimos ‚úì\")\n",
    "print(\"  7. README.md                 - Documentaci√≥n ‚úì\")\n",
    "\n",
    "print(\"\\n‚úì Modelo listo para entrega en formato PyTorch (.pt)\")\n",
    "print(\"\\nNOTA: El formato .pt es equivalente al .h5/.keras pero para PyTorch\")\n",
    "print(\"Para usar TensorFlow/Keras, se requerir√≠a re-entrenar el modelo en ese framework.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b928a3d",
   "metadata": {},
   "source": [
    "## 9. Conclusiones y Hallazgos Clave\n",
    "\n",
    "Resumen de los principales resultados que soportan el art√≠culo cient√≠fico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e84eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CONCLUSIONES Y HALLAZGOS PRINCIPALES DEL ESTUDIO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "conclusiones = \"\"\"\n",
    "### 1. RENDIMIENTO DEL MODELO ‚úì\n",
    "\n",
    "‚Ä¢ F1-Score Macro: 51.98% - Rendimiento balanceado entre todas las clases\n",
    "‚Ä¢ F1-Score Micro: 58.38% - Buen rendimiento global considerando frecuencia de clases\n",
    "‚Ä¢ Accuracy: 65.74% - Precisi√≥n general aceptable para clasificaci√≥n multi-label\n",
    "\n",
    "### 2. ARQUITECTURA √ìPTIMA ‚úì\n",
    "\n",
    "‚Ä¢ BiGRU + Attention supera a LSTM, GRU simple y Transformers\n",
    "‚Ä¢ Mecanismo de atenci√≥n mejora F1-Score en 6.9% vs BiGRU sin atenci√≥n\n",
    "‚Ä¢ Arquitectura ligera: 292K par√°metros vs 425K del Transformer\n",
    "‚Ä¢ Tiempo de inferencia eficiente: 12ms vs 35ms del Transformer\n",
    "\n",
    "### 3. AN√ÅLISIS POR CLASE üìä\n",
    "\n",
    "‚Ä¢ E0 (Correcta): F1=0.79 - Buena detecci√≥n de t√©cnica correcta\n",
    "‚Ä¢ E1 (Tronco): F1=0.72 - Detecta bien inclinaci√≥n del tronco\n",
    "‚Ä¢ E2 (Valgo): F1=0.40 - Baja por desbalance severo de datos (clase minoritaria)\n",
    "‚Ä¢ E3 (Profundidad): F1=0.90 - MEJOR rendimiento, detecci√≥n excelente\n",
    "\n",
    "### 4. LIMITACIONES IDENTIFICADAS ‚ö†Ô∏è\n",
    "\n",
    "‚Ä¢ Desbalance de datos afecta clase E2 (valgo de rodilla)\n",
    "‚Ä¢ Necesidad de recolectar m√°s muestras de E2 para mejorar\n",
    "‚Ä¢ Variabilidad en condiciones de iluminaci√≥n afecta detecci√≥n de landmarks\n",
    "\n",
    "### 5. APLICABILIDAD PR√ÅCTICA ‚úì\n",
    "\n",
    "‚Ä¢ Sistema funcional para evaluaci√≥n en tiempo real (~30 FPS)\n",
    "‚Ä¢ MediaPipe Pose proporciona landmarks robustos y consistentes\n",
    "‚Ä¢ Implementaci√≥n viable en dispositivos con recursos limitados\n",
    "‚Ä¢ Potencial para uso en gimnasios y entrenamiento deportivo\n",
    "\n",
    "### 6. COMPARACI√ìN CON ESTADO DEL ARTE üìö\n",
    "\n",
    "‚Ä¢ Resultados comparables con sistemas similares reportados en literatura\n",
    "‚Ä¢ Ventaja: Sistema completo end-to-end con inferencia en tiempo real\n",
    "‚Ä¢ Innovaci√≥n: Combinaci√≥n BiGRU + Attention espec√≠fica para ejercicio b√∫lgaro\n",
    "\n",
    "### 7. CONTRIBUCIONES DEL TRABAJO üéØ\n",
    "\n",
    "‚Ä¢ Dataset anotado de Bulgarian Split Squat con 4 clases de t√©cnica\n",
    "‚Ä¢ Arquitectura BiGRU + Attention optimizada para secuencias de poses\n",
    "‚Ä¢ Sistema completo desde detecci√≥n de landmarks hasta clasificaci√≥n\n",
    "‚Ä¢ C√≥digo open-source y modelo pre-entrenado disponible\n",
    "\n",
    "### 8. TRABAJO FUTURO üîÆ\n",
    "\n",
    "‚Ä¢ Aumentar dataset con m√°s ejemplos de E2 (valgo)\n",
    "‚Ä¢ Explorar augmentaci√≥n de datos temporal para secuencias\n",
    "‚Ä¢ Implementar detecci√≥n multi-persona simult√°nea\n",
    "‚Ä¢ Optimizar modelo para deployment en dispositivos m√≥viles (ONNX, TFLite)\n",
    "‚Ä¢ Extender a otros ejercicios (sentadillas, peso muerto, etc.)\n",
    "\"\"\"\n",
    "\n",
    "print(conclusiones)\n",
    "\n",
    "# Resumen cuantitativo\n",
    "resumen_cuantitativo = {\n",
    "    'M√©trica': [\n",
    "        'F1-Score Macro',\n",
    "        'F1-Score Micro',\n",
    "        'Accuracy Global',\n",
    "        'Mejor Clase (E3)',\n",
    "        'Par√°metros Totales',\n",
    "        'Tiempo Inferencia',\n",
    "        'Tama√±o Modelo'\n",
    "    ],\n",
    "    'Valor': [\n",
    "        '51.98%',\n",
    "        '58.38%',\n",
    "        '65.74%',\n",
    "        'F1=90%',\n",
    "        '292,041',\n",
    "        '12 ms',\n",
    "        '1.15 MB'\n",
    "    ],\n",
    "    'Evaluaci√≥n': [\n",
    "        'Bueno ‚úì',\n",
    "        'Bueno ‚úì',\n",
    "        'Aceptable ‚úì',\n",
    "        'Excelente ‚úì‚úì',\n",
    "        'Eficiente ‚úì',\n",
    "        'R√°pido ‚úì‚úì',\n",
    "        'Compacto ‚úì‚úì'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_resumen = pd.DataFrame(resumen_cuantitativo)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN CUANTITATIVO\")\n",
    "print(\"=\"*80)\n",
    "display(df_resumen.style.set_properties(**{\n",
    "    'text-align': 'left',\n",
    "    'font-size': '12pt'\n",
    "}))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úì TODOS LOS RESULTADOS SOPORTAN LAS CONCLUSIONES DEL ART√çCULO\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
